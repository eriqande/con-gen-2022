{"title":"A brief introduction to Snakemake","markdown":{"headingText":"A brief introduction to Snakemake","containsRefs":false,"markdown":"\n## Narrative Explanation of Snakemake\n\nFor managing these sorts of bioinformatic workflows there is a Python-based\nframework called [Snakemake](https://snakemake.readthedocs.io/en/stable/)\nthat is well-supported, flexible, and incredibly powerful.\nUnderstanding how Snakemake works and becoming familiar with its many\nfeatures involves a non-trivial learning curve; however, for anyone spending\na sizable chunk of their graduate career managing bioinformatic analyses, or for anyone that is\na lab bioinformatician running bioinformatic workflows across\nmany species (for example), the benefits of learning\nSnakemake will continue to pay dividends for years to come.\n\n\nSomeone who has mastered all the topics in Part I of this handbook (Unix programming,\nworking on remote computers, etc.) certainly will have the skills to write\nwhat I will call _input-oriented_, _forward-marching_ workflows. I call these\n\"forward-marching\" because they start from a set of\ninput files (for example files of sequences from a sequencer), and then\nthe workflow is defined as a series of sequential steps, one after the other.\nThey are \"input-oriented\" in the sense that such a workflow starts\nwith a series of inputs, but the workflow itself doesn't really know\nwhat it is trying to produce from those inputs until it has run all the\nway through and actually turned those inputs into outputs.\nFor example, all the input\nfiles might get trimmed or cleaned, then they would all get mapped to a genome,\nand then those mapped sequences would be used to call variants, so as to\nfind SNPs in the data, etc.  If you were writing this in an\ninput-oriented, forward-marching fashion, then, to deal with the fact that you had multiple files of\nDNA sequences (for example, one for each individual bird or fish that had\nbeen sampled), you might write Unix `for` loops to cycle over all the input files\nas in Section&nbsp;\\@ref(unix-for-loops), or, you could define a SLURM job array to start a separate job\ninstance for each input file, as in Section&nbsp;\\@ref(slurm-job-arrays).  In each case,\nyou would have to do some extra programming to deal with the different input files, and\nif one of the steps of your workflow failed on just one, or a few, of the files,\nyou might spend a large amount of time tracking those failures down and than\nmanually re-running that small number of jobs.\n\nBy contrast, Snakemake takes a different approach to managing workflows.\nWe will call it an _output-oriented_, _backward-looking_ approach. We call it\nthat because workflows in Snakemake are defined first and foremost in terms of the _output files_\nthat are desired, along with instructions on how to create those output files\nfrom necessary input files and bioinformatic programs.  They are _backward-looking_\nin the sense that, once you have developed a Snakemake workflow, you get results by\ntelling Snakemake which output files you\nwant to create, and then it \"looks backwards\" through the workflow to determine which\ninput files are needed to create the requested outputs.  Sometimes it has to look backwards\nthrough several steps before it identifies all the necessary input files.\nOnce it has found those necessary inputs, it then runs forward through the steps to\ncreate the output files. In this phase, the workflow looks like it is \"forward-marching\", in the\nsense that outputs are being created from inputs.  But, in order to get to that\n\"forward-running\" phase, Snakemake had to look backward to figure out what inputs to use.\n\nThe above constitutes some subtle points, that might not be clear upon first reading,\nbut we will try to summarize it in a few pithy phrases:\n\n- A workflow defined as a typical Unix shell script can be thought of as a process that runs\nforward. You give it a lot of input files and it just cranks through a bunch of steps until\nthe output files are made.\n- A workflow defined with Snakemake works differently. First you define the workflow in terms\nof a series of \"rules.\" Then, when you request any given set of output files, Snakemake\nwill look backwards through\nthe rules of the workflow and figure out exactly which steps must be performed, on which input\nfiles, in order to create the requested output files. Once it has determined that,\nit runs just those necessary steps.\n\nThere are many advantages to this output-oriented, backward-looking approach:\n\n1. If your workflow has many steps, and some of them have already been run,\nthen Snakemake automatically recognizes that, and will not re-run steps\nin the workflow that have already been completed. In an input-oriented system (like\na traditional Unix script), you would have to spend the time to figure out\nwhich steps had already been run, and then run your script only from that\npoint forward.  Doing so can be a hassle and can also be prone to errors.\n2. A workflow defined by Snakemake, being explicit about the inputs needed\nfor each step, naturally defines \"work units\" that can be run independently of\none another.  Accordingly, Snakemake, itself, can break a huge bioinformatic workflow\ninto a number of small jobs that can be run in parallel, saving you, the user,\nfrom having to write scripts to launch a series of SLURM job arrays.\n3. The fact that Snakemake automatically keeps track of which inputs already\nexist---and which might still need to be generated---provides huge benefits when some of your jobs fail.\nAnyone who has used a cluster has stories about jobs that inexplicably fail.  Without a workflow\nmanagement system like Snakemake, you can spend almost as much of your own time managing these\nfailed jobs as it took to launch all the jobs in the first place.\n\nIn addition to these obvious advantages of the output-oriented approach, Snakemake also\nincludes a number of features that make it easy to use your workflow on a variety of\ndifferent platforms.  It is tightly integrated with conda (Section&nbsp;\\@ref(miniconda)),\nletting the user define\nconda environments for each step in the workflow.  This means that if you move your whole\nworkflow to a new cluster, you don't have to spend any time coordinating the installation\nof the programs you need---if you set things up properly with Snakemake and conda,\nthat will happen automatically.\nIf you distribute your workflows to other people to use, this is particularly helpful, since\nyou will spend far less time assisting them in setting up their computer environment to run\nyour workflow. Snakemake can also be customized to work in your own cluster environment.  Finally,\nthere are interfaces to allow your Snakemake workflows to run seamlessly in the cloud.\n\nFull  documentation for Snakemake can be found at\n[https://snakemake.readthedocs.io/en/stable/](https://snakemake.readthedocs.io/en/stable/).\nThis documentation is comprehensive, but can feel a little daunting at first.\nOn the other hand, the developers of Snakemake also provide an excellent and accessible\ntutorial at\n[https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html](https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html).\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"snakemake.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.36","bibliography":["references.bib"],"editor":"source","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"snakemake.pdf"},"language":{},"metadata":{"block-headings":true,"bibliography":["references.bib"],"editor":"source","documentclass":"scrreprt"},"extensions":{"book":{}}}}}